Negative:
when the mapping is not set, you will lose all the teamcity settings on container shutdown.
/pre/  fix, and it always works when i run it manually but never works when it runs through teamcity.
when the teamcity build agent executes my bash script it fails to restore nuget packages with following message: .
chromedriver does not start a browser and causes tests to fail when run selenium tests from teamcity and jenkins, which both give same error messages: .
turns out there was a duplicate dns entry for the teamcity server in samba which was confusing the agents!
this might be a teamcity bug where the docker.server.ostype is not being set when running windows containers in docker desktop for windows (windows server 2016).
i have been trying to set up a teamcity instance in docker, and when i try to migrate from the internal db - which i successfully removed - teamcity does n't find the jdbc driver for postgresql with the error: /code_segment/
the problem is that teamcity always shows build as succeeded although i can see in my jmeter report that some assertions from the test are failing.
/pre/  this works perfectly from command line, but teamcity shows different errors with exit codes 4, 6 or even does n't do anything without an error.
teamcity sometimes kills my build with a (double) keyboard interrupt, and i have no idea why.
unable to upload zip file created as artifacts in teamcity build using file specs to artifactory tried all types of patterns and file specs unable to upload, it not finding the artifact .
but teamcity gives an error saying it cannot find the symbol: global_tracker.xml.
the exception was handled, and the cleanup that got triggered by the exception would have resulted in the process getting shut down anyway (through another means), but before that cleanup was finished, teamcity was killing our build: which ironically meant that the process never did get shut down.
if you can execute the tf commands successful manunally on the agent machine but failed when build by teamcity, please check if the agent configuration for teamcity use run as the same account as your local machine.
the project builds without any problem locally, but on my teamcity build server (windows server 2016), i 'm consistently getting the following error: .
this works perfectly on local but while generating teamcity build it get failed.
however, when i set the same artifactory ssl url in the teamcity console under integrated artifactory server url configuration and hit the test connection it fails with the error below.
everytime i try to build a maven project hosted on a gitlab server  with teamcity, i get an error from the buildagent.
when i run my command through cmd the code will compile correctly so this problem seems to only happen when running through teamcity.
when teamcity is executing first configuration, i 'm receiving random error messages every 5-10 builds: .
but i found error when i deploy in weblogic through teamcity.
you could disable to step in teamcity leaving it for reference should you run into the issue again.
in teamcity i would add a build failure condition that would compare the number of unit tests in the current build with the previous build, and if it (significantly) drops, it would fail the build.
i have having trouble download artifacts from teamcity.
the third build-step, also generated by teamcity give me a problem.
due to some mistakes i made in configuring some builds my teamcity nuget feed has the wrong artefacts in some of the feeds.
teamcity did n't really provide an accurate error.
seems like the computer where teamcity is running fails to connect to port 993. .
be careful because the work and temp directory might be cleared by teamcity agent and your cache will not be stable.
i got an error while building a project in teamcity.
while building solution on teamcity server i am getting below error .
a teamcity pipeline randomly stopped working today, and it has an error i cannot seem to find elsewhere.
note: i wondered if its new setup issue, so i reinstalled teamcity from scratch and it works fine until i restart the service, then the same issue.
i say supposed to, because every once in a while it throws this error and i ca n't seem to either catch it (locally even) or suppress it, so it breaks the teamcity run.
my script on teamcity always shows success irrespective of my tests failing or passing on the automation tool testcomplete.
however, when i try to do the same in teamcity using the 'command line' runner type, it just hangs.
but using this approach for some reason reporter does not work properly and teamcity does not detect all tests that were run.

Positive:
because i could imagine that teamcity employs some sort of safeguard mechanism that prevents certain changes on the server it 's run from.
first of all, i think this is more of a linux issue as the problem seems to be on a linux-flavoured docker container, but i 'm happy to accept that i can do something to the teamcity config to overcome this.
this was a bug, which is fixed in teamcity 2018.1.3.
